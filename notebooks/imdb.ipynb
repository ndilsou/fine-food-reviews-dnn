{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data available at:\n",
    "https://www.kaggle.com/kaushik3497/imdb-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Sequence, Dict, Callable, Any, List, Pattern, Union, Iterable, overload\n",
    "import nltk\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, PunktSentenceTokenizer\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger\n",
    "from nltk.corpus import brown\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import toolz as tz\n",
    "from pattern.en import parse\n",
    "import toolz.curried as tzc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pattern\n",
    "from pattern.web import plaintext\n",
    "\n",
    "import bs4\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp, feature_extraction\n",
    "from sklearn import naive_bayes, linear_model, metrics, model_selection, svm, ensemble\n",
    "from sklearn import pipeline\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = Path('../data/labeledTrainData.tsv')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = train_file.open()\n",
    "records = csv.DictReader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', '\"5814_8\"'),\n",
       "             ('sentiment', '1'),\n",
       "             ('review',\n",
       "              '\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = next(records)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head ../data/labeledTrainData.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(train_file, sep='\\t', quoting=csv.QUOTE_NONE) \n",
    "# We'll handle quotes manually.\n",
    "\n",
    "raw_train_dataset, raw_test_dataset = train_test_split(raw_dataset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_train_dataset, raw_devtest_dataset = train_test_split(raw_observable_dataset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_quotes_and_ids(dataset):\n",
    "    no_id_dataset = dataset.drop('id', 'columns')\n",
    "    no_id_dataset['review'] = no_id_dataset['review'].str.strip('\\\"\"')\n",
    "    return no_id_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>1</td>\n",
       "      <td>This movie is a ripoff of James Cain's novel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>0</td>\n",
       "      <td>Trot out every stereotype and misrepresentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20263</th>\n",
       "      <td>1</td>\n",
       "      <td>Good story and excellent animation. The influe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15504</th>\n",
       "      <td>1</td>\n",
       "      <td>I saw this jolly little film at age 10/11 in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>1</td>\n",
       "      <td>The film as entertainment is very good and Jim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24626</th>\n",
       "      <td>1</td>\n",
       "      <td>CAT SOUP has two \\\"Hello Kitty\\\"-type kittens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>0</td>\n",
       "      <td>Saying this movie is extremely hard to follow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11738</th>\n",
       "      <td>0</td>\n",
       "      <td>the IMDb guidelines state that you have to dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24617</th>\n",
       "      <td>1</td>\n",
       "      <td>I think Charlotte Gainsbourg is one of the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>0</td>\n",
       "      <td>To be honest I knew what to expect before I wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                             review\n",
       "23705          1  This movie is a ripoff of James Cain's novel, ...\n",
       "18761          0  Trot out every stereotype and misrepresentatio...\n",
       "20263          1  Good story and excellent animation. The influe...\n",
       "15504          1  I saw this jolly little film at age 10/11 in 1...\n",
       "7990           1  The film as entertainment is very good and Jim...\n",
       "24626          1  CAT SOUP has two \\\"Hello Kitty\\\"-type kittens ...\n",
       "6342           0  Saying this movie is extremely hard to follow ...\n",
       "11738          0  the IMDb guidelines state that you have to dec...\n",
       "24617          1  I think Charlotte Gainsbourg is one of the bes...\n",
       "4558           0  To be honest I knew what to expect before I wa..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = strip_quotes_and_ids(raw_train_dataset)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0           11243\n",
       "1           11257"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    22500.000000\n",
      "mean      1326.577556\n",
      "std       1005.272169\n",
      "min         52.000000\n",
      "25%        702.000000\n",
      "50%        979.000000\n",
      "75%       1619.000000\n",
      "max      13708.000000\n",
      "Name: review, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_lengths = dataset['review'].map(len)\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "review_lengths.hist(bins=100);\n",
    "print(review_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 1\n",
      "Goebbels motivation in backing down was not explored. In the aftermath of Stalingrad the Reich had decided to go for 'total war'. This is referred to in the film. Part of this was to use women in the war effort, which Germany had not previously done to any great extent. An SS massacre of women would have faced Goebbels with a public relations disaster of massive proportion. His preference was to make the problem go away as quietly as possible, on the basis that the Jewish men could always be rounded up later. I understand the majority survived the war.<br /><br />His other problem was that the 'Red' Berlin had never been very enthusiastically behind the Nazi cause and had to be handled cautiously. Again a massacre of women could have cost the Nazis what mediocre level of support they had in their capital city.<br /><br />It was interesting that the majority of SS uniforms showed patches which indicated that the men wearing them were not of German nationality, but were from German origins in other countries such as Lithuania or Latvia\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.sample(1)\n",
    "print(f'sentiment: {sample.values[0, 0]}')\n",
    "review = sample.values[0, 1]\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4.BeautifulSoup(sample.values[0, 1]).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* need to remove escaped quotes.\n",
    "* need to remove html tags\n",
    "* possibly parentheses. [ (][)}{ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_raw_english_contractions():\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions')\n",
    "    soup = bs4.BeautifulSoup(resp.text)\n",
    "    table = soup.find('table', attrs={'class': 'wikitable'})\n",
    "    table.find('tbody')\n",
    "    data = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        data.append([\n",
    "            c.get_text()\\\n",
    "                .strip()\\\n",
    "                .replace(r'\\[.+\\]', '')\n",
    "            for c in cols\n",
    "        ])\n",
    "    return data\n",
    "\n",
    "def get_curated_english_contractions():\n",
    "    with open('../data/curated_contractions.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        contractions = [row for row in reader]\n",
    "    return contractions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_file = Path('../data/raw_contractions.csv')\n",
    "if not contraction_file.exists():\n",
    "    raw_contractions = get_raw_english_contractions()\n",
    "    with contraction_file.open('wt') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(raw_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp ../data/raw_contractions.csv ../data/curated_contractions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTES_PATTERN = [(r'\\\\\\\"|\\\\\\'', '')]\n",
    "PARENTHESIS_PATTERN = [(r'[]}{)(]', '')]\n",
    "ENGLISH_CONTRACTIONS = get_curated_english_contractions()\n",
    "\n",
    "# We manually curate the stopwords to not remove words that may indicate some form of polarity.\n",
    "STOPWORDS = [\n",
    "    'the', '.', 'a', 'and', ',', 'of', 'to', 'is', 'this', \n",
    "    'it',  'that', 'i', 'but', 'for', 'with', \n",
    "    'was', 'as', 'have', 'on', \"'s\", 'has', 'are',\n",
    "    'be', 'one', 'you', 'at', 'all', 'an', 'from', \n",
    "    'by', 'like', 'so', 'who', 'they', 'his', 'do', \n",
    "    'there', 'about', 'if',  'or', 'he', 'can', 'what',\n",
    "    'when', 'would',  'had',\n",
    "    'time', 'even', 'only', 'will',  'see', 'my', \n",
    "    'which', 'me', 'than', 'did', 'does',\n",
    "    'were', 'their', 'could', 'get', 'been', 'other',\n",
    "    'into', 'her', 'also', 'how', 'because'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_quotes(text, pattern: Pattern = QUOTES_PATTERN):\n",
    "    '''\n",
    "    removes escaped quotes. (\\' or \\\")\n",
    "    '''\n",
    "    text = pattern.sub('', text)\n",
    "    return text\n",
    "\n",
    "def clean_html(text):\n",
    "    '''\n",
    "    removes html tags.\n",
    "    '''\n",
    "    return plaintext(text)\n",
    "\n",
    "@tz.curry\n",
    "def filter_stopwords(stopwords, tokens):\n",
    "    return tz.filter(lambda t: t not in stopwords, tokens)\n",
    "\n",
    "class RegexpReplacer:\n",
    "    def __init__(self, patterns: Sequence[Tuple[Union[str, re.Pattern], str]]):\n",
    "        self.patterns = [(re.compile(p), r) for p, r in patterns]\n",
    "    \n",
    "    def replace(self, text: str) -> str:\n",
    "        for pattern, repl in self.patterns:\n",
    "            text = pattern.sub(repl, text)\n",
    "        return text\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        return self.replace(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_remover = RegexpReplacer(QUOTES_PATTERN)\n",
    "parenthesis_remover = RegexpReplacer(PARENTHESIS_PATTERN)\n",
    "contraction_replacer = RegexpReplacer(ENGLISH_CONTRACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "QuoteRemover\n",
      "\n",
      "Goebbels motivation in backing down was not explored. In the aftermath of Stalingrad the Reich had decided to go for 'total war'. This is referred to in the film. Part of this was to use women in the war effort, which Germany had not previously done to any great extent. An SS massacre of women would have faced Goebbels with a public relations disaster of massive proportion. His preference was to make the problem go away as quietly as possible, on the basis that the Jewish men could always be rounded up later. I understand the majority survived the war.<br /><br />His other problem was that the 'Red' Berlin had never been very enthusiastically behind the Nazi cause and had to be handled cautiously. Again a massacre of women could have cost the Nazis what mediocre level of support they had in their capital city.<br /><br />It was interesting that the majority of SS uniforms showed patches which indicated that the men wearing them were not of German nationality, but were from German origins in other countries such as Lithuania or Latvia\n",
      "\n",
      "\n",
      "ParenthesisRemover\n",
      "\n",
      "Goebbels motivation in backing down was not explored. In the aftermath of Stalingrad the Reich had decided to go for 'total war'. This is referred to in the film. Part of this was to use women in the war effort, which Germany had not previously done to any great extent. An SS massacre of women would have faced Goebbels with a public relations disaster of massive proportion. His preference was to make the problem go away as quietly as possible, on the basis that the Jewish men could always be rounded up later. I understand the majority survived the war.<br /><br />His other problem was that the 'Red' Berlin had never been very enthusiastically behind the Nazi cause and had to be handled cautiously. Again a massacre of women could have cost the Nazis what mediocre level of support they had in their capital city.<br /><br />It was interesting that the majority of SS uniforms showed patches which indicated that the men wearing them were not of German nationality, but were from German origins in other countries such as Lithuania or Latvia\n",
      "\n",
      "\n",
      "ContractionReplacer\n",
      "\n",
      "Goebbels motivation in backing down was not explored. In the aftermath of Stalingrad the Reich had decided to go for 'total war'. This is referred to in the film. Part of this was to use women in the war effort, which Germany had not previously done to any great extent. An SS massacre of women would have faced Goebbels with a public relations disaster of massive proportion. His preference was to make the problem go away as quietly as possible, on the basis that the Jewish men could always be rounded up later. I understand the majority survived the war.<br /><br />His other problem was that the 'Red' Berlin had never been very enthusiastically behind the Nazi cause and had to be handled cautiously. Again a massacre of women could have cost the Nazis what mediocre level of support they had in their capital city.<br /><br />It was interesting that the majority of SS uniforms showed patches which indicated that the men wearing them were not of German nationality, but were from German origins in other countries such as Lithuania or Latvia\n",
      "\n",
      "\n",
      "CleanHtml\n",
      "\n",
      "Goebbels motivation in backing down was not explored. In the aftermath of Stalingrad the Reich had decided to go for 'total war'. This is referred to in the film. Part of this was to use women in the war effort, which Germany had not previously done to any great extent. An SS massacre of women would have faced Goebbels with a public relations disaster of massive proportion. His preference was to make the problem go away as quietly as possible, on the basis that the Jewish men could always be rounded up later. I understand the majority survived the war.\n",
      "\n",
      "His other problem was that the 'Red' Berlin had never been very enthusiastically behind the Nazi cause and had to be handled cautiously. Again a massacre of women could have cost the Nazis what mediocre level of support they had in their capital city.\n",
      "\n",
      "It was interesting that the majority of SS uniforms showed patches which indicated that the men wearing them were not of German nationality, but were from German origins in other countries such as Lithuania or Latvia\n"
     ]
    }
   ],
   "source": [
    "unquoted_review = quote_remover(review)\n",
    "print('\\n\\nQuoteRemover\\n')\n",
    "print(unquoted_review)\n",
    "\n",
    "no_parens_review = parenthesis_remover(unquoted_review)\n",
    "print('\\n\\nParenthesisRemover\\n')\n",
    "print(no_parens_review)\n",
    "\n",
    "decontracted_review = contraction_replacer(no_parens_review)\n",
    "print('\\n\\nContractionReplacer\\n')\n",
    "print(decontracted_review)\n",
    "\n",
    "cleaned_html = clean_html(decontracted_review)\n",
    "print('\\n\\nCleanHtml\\n')\n",
    "print(cleaned_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = PunktSentenceTokenizer()\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "tokenize_text = tzc.compose(tzc.mapcat(word_tokenizer.tokenize), sent_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Goebbels',\n",
       " 'motivation',\n",
       " 'in',\n",
       " 'backing',\n",
       " 'down',\n",
       " 'was',\n",
       " 'not',\n",
       " 'explored',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'aftermath',\n",
       " 'of',\n",
       " 'Stalingrad',\n",
       " 'the',\n",
       " 'Reich',\n",
       " 'had',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'go']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenize_text(cleaned_html))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Goebbels',\n",
       " 'motivation',\n",
       " 'in',\n",
       " 'backing',\n",
       " 'down',\n",
       " 'not',\n",
       " 'explored',\n",
       " 'In',\n",
       " 'aftermath',\n",
       " 'Stalingrad',\n",
       " 'Reich',\n",
       " 'decided',\n",
       " 'go',\n",
       " \"'total\",\n",
       " 'war',\n",
       " \"'\",\n",
       " 'This',\n",
       " 'referred',\n",
       " 'in',\n",
       " 'film']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter_stopwords(STOPWORDS, tokenize_text(cleaned_html)))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text, func):\n",
    "    '''\n",
    "    clean and tokenize a text.\n",
    "    tokenize: bool indicate if the function should tokenize.\n",
    "    resolve: bool indicates if the iterator should be outputted to a list or not.\n",
    "    '''\n",
    "    return func(text)\n",
    "    \n",
    "def create_corpus_processor(*steps):\n",
    "    '''\n",
    "    Produces a function that can be applied to a corpus of document, applying each step in series to each document.\n",
    "    '''\n",
    "                   \n",
    "    def process_corpus(corpus: Iterable[str], \n",
    "                       map: Callable[[Callable, Iterable], Iterable] = tz.map,\n",
    "                       collect=None) -> Iterable[str]:\n",
    "        '''\n",
    "        Process a corpus, represented as an iterable of text into a clean and tokenized corpus.\n",
    "        Downstream tasks can be mapped to the return iterable.\n",
    "        You can provide a custom map, for example to process the items in parallel.\n",
    "        '''\n",
    "        \n",
    "        func = tz.compose(collect or tz.identity, *reversed(steps)) # compose applies last step first.\n",
    "        apply_steps = partial(process_text, func=func)\n",
    "        processed_corpus = tz.map(apply_steps, corpus)\n",
    "        return processed_corpus\n",
    "    \n",
    "    return process_corpus\n",
    "\n",
    "def doc2bow(doc):\n",
    "    '''\n",
    "    Generates Bag of Word features\n",
    "    '''\n",
    "    return {word: True for word in doc}\n",
    "\n",
    "def doc2boc(doc):\n",
    "    '''\n",
    "    Generates Bag of Counts features\n",
    "    '''\n",
    "    return Counter(doc)\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, tokens):\n",
    "        self._vocab = Counter(tokens)\n",
    "    \n",
    "    def words(self):\n",
    "        return self._vocab.keys()\n",
    "    \n",
    "    def most_common(self, n):\n",
    "        return list(tz.pluck(0, self._vocab.most_common(n)))\n",
    "    \n",
    "    def frequencies(self, n=None):\n",
    "        if n:\n",
    "            freq = { k: v for k, v in self._vocab.most_common(n) }\n",
    "        else: \n",
    "            freq = dict(self._vocab)\n",
    "        return freq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_steps = tz.compose()\n",
    "process_corpus = create_corpus_processor(quote_remover, \n",
    "                        parenthesis_remover, \n",
    "                        contraction_replacer, \n",
    "                        clean_html,\n",
    "                        str.lower,\n",
    "                        sent_tokenizer.tokenize,\n",
    "                        word_tokenizer.tokenize_sents\n",
    "#                         tokenize_text,\n",
    "#                         filter_stopwords(STOPWORDS),\n",
    "#                         tzc.map(stemmer.stem)\n",
    "                                        )\n",
    "                        \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    map_func = partial(executor.map, chunksize=500)\n",
    "    processed_corpus = list(process_corpus(dataset['review'], map_func, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'a',\n",
       " 'ripoff',\n",
       " 'of',\n",
       " 'james',\n",
       " 'cain',\n",
       " \"'s\",\n",
       " 'novel',\n",
       " ',',\n",
       " 'the',\n",
       " 'postman',\n",
       " 'always',\n",
       " 'rings',\n",
       " 'twice',\n",
       " '.']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tz.concat(processed_corpus))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_terms = nltk.corpus.stopwords.words('english')\n",
    "phrases = Phrases(tz.concat(processed_corpus), min_count=5, threshold=25.0, common_terms=common_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_phrases = tz.pipe(phrases.export_phrases(tz.concat(processed_corpus)), tzc.pluck(0), tzc.map(bytes.decode), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postman always', 'rings twice', 'male and female', 'male lead', 'lana turner', 'john garfield', 'lana turner', 'middle of nowhere', '100 %', 'much better', 'human nature', 'warner brothers', 'thank goodness', 'even though', 'sexual innuendo', 'well done', 'vhs copy', 'point of view', '5 stars', 'young boy', 'despite the fact', '10 stars', 'vhs copy', 'jimmy stewart', 'well done', 'vera miles', 'every aspect', 'motion picture', \"1950 's\", 'everything else', 'hard to follow', 'film festival', 'opening sequence', 'little bit', 'next day', 'woman named', 'takes place', 'slap in the face', 'barbara steele', 'music score', 'film festival', 'plot line', 'born killers', 'ever seen', '... ..', 'sunday afternoon', 'santa claus', 'santa claus', 'years later', 'dan jansen']\n"
     ]
    }
   ],
   "source": [
    "print(found_phrases[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_corpus[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i kind of feel like a genius; i feel like i am the only one who saw through this fake film.',\n",
       " 'i watched it three times, once with commentary, and i found myself getting annoyed at all the close-ups, all the times the screen just blacks out, and worst of all, i feel the film never really resolves anything.',\n",
       " 'yes, the priest dies, but he did not really seem at peace with the town that gave him so much grief, or with himself.',\n",
       " 'that and he was an idiot.',\n",
       " 'if it were not for the commentary by peter cowie which explained not only the movie but the book it came from, i would not have been able to stomach it at all.',\n",
       " 'i enjoy french movies, but this is one that was completely absurd.',\n",
       " 'diary of a country priest is filmed in beautiful black and white photography but, that alone cannot save this deadly dull tripe.',\n",
       " 'scene after scene of extreme close-ups where characters do not say anything until the camera cuts away and goes to a black out do not make an interesting or relevant story.',\n",
       " \"how this film ever became a classic is mind boggling: it reminds me more of the emperor's new clothes.\",\n",
       " \"yes, claude laydu's performance is heartfelt and thought provoking, if you are a sadist, but this film left me feeling empty because overall it is a weak impression of the catholic priesthood, which is an ignoble and inglorious institution of corruption.\",\n",
       " \"the young priest's triumph over the countess's pride is a weak scene but 90% of the film will drag you down with its dreary introspection and window into the young priest's melancholy thoughts.\",\n",
       " 'this priest does not come across so much as being humble as he does just plain pitiful.',\n",
       " 'being that i do not speak or understand french i was looking forward to doing the english subtitle thing to help understand the film.',\n",
       " 'well, the english subtitle is at times impossible to view/read and the text rolls by so quickly that there was much i could not read and i am not a particularly slow reader - i just finished dostoyevsky in 3 days.',\n",
       " 'i really wanted to like this film .',\n",
       " 'i try out everything chosen by the criterion collection, and yet can not see why in many ways this one merits some sort of critical nod.',\n",
       " 'however, i sat through this entire two hour film yearning to feel some sort of empathy for the main character, and it never materialized.',\n",
       " 'he just seemed like a victim rather than a fighter.',\n",
       " 'and for that, i say it stunk.']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = bigram[processed_corpus[2020]]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5888111\n"
     ]
    }
   ],
   "source": [
    "corpus_word_count = sum(tz.map(len, tz.concat(processed_corpus)))\n",
    "print(corpus_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = FastText(size=64,word_ngrams=2, min_count=3)\n",
    "embeddings.build_vocab(tz.concat(processed_corpus))\n",
    "embeddings.train(tz.concat(processed_corpus), epochs=10, total_examples=corpus_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38923"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30184388"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.wv.similarity('cheval', 'movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tz.curry\n",
    "def doc2vec(embeddings, doc):\n",
    "    '''\n",
    "    Returns the mean embedding for a document structured as a list of tokens\n",
    "    '''\n",
    "    return embeddings.wv[doc].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2fasttext = doc2vec(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1509267e+00,  1.1471021e+00,  1.0719388e-01,  7.1382485e-02,\n",
       "       -2.3577134e-01, -1.8125235e-01, -2.1315233e-01, -3.4934050e-01,\n",
       "        4.3128604e-01, -1.7628764e-01, -1.3326916e-01, -8.2983619e-01,\n",
       "        1.5846214e-01, -1.2428968e-01,  3.7927589e-01, -2.7213514e-01,\n",
       "       -6.2164396e-01,  3.3190385e-01, -8.2511529e-02,  3.0340219e-01,\n",
       "        2.5930601e-01,  2.6394856e-01,  3.6116439e-01,  1.9499652e-01,\n",
       "        2.8055090e-01,  4.7445619e-01,  1.4172318e+00,  4.0309167e-01,\n",
       "       -2.9121533e-01,  9.1205418e-01, -7.1901447e-01,  1.8629999e-01,\n",
       "        1.5092591e+00,  6.5438086e-01, -7.1998078e-01,  8.4510601e-01,\n",
       "        7.4078429e-01,  1.7003997e-01, -2.3665012e-01,  1.4608146e-01,\n",
       "        1.0573075e-02,  3.1596339e-01, -2.5961956e-01,  7.3504192e-01,\n",
       "       -9.5579788e-05, -3.0131191e-01,  4.6119997e-01, -2.0330088e-01,\n",
       "        5.9019551e-02,  1.5072658e+00,  6.6632855e-01,  1.8196637e-02,\n",
       "        7.6880246e-01, -7.6872224e-01,  2.6393605e-02,  3.0591252e-01,\n",
       "       -1.5400064e+00, -5.4852211e-01, -2.9158473e-01,  5.0397026e-03,\n",
       "       -1.5342596e+00, -3.9011875e-01, -7.0868099e-01,  9.4936931e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2fasttext(tz.concat(processed_corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = Vocabulary(tz.concat(processed_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78992"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in': 83710, 'not': 57001, 'movi': 45746, 'film': 42745, '!': 22355, 'just': 15989, 'out': 14985, '?': 14537, 'some': 14073, 'good': 13470, 'make': 13064, 'more': 12809, 'she': 12728, 'veri': 12648, 'charact': 12567, 'watch': 12356, 'stori': 11665, 'up': 11188, 'no': 11147, '...': 10791, 'realli': 10559, 'we': 9849, 'scene': 9436, \"'\": 9193, ':': 9083, 'well': 8973, '-': 8862, 'look': 8783, 'show': 8760, 'much': 8726, 'end': 8524, 'go': 8414, 'peopl': 8383, 'bad': 8238, 'great': 8165, 'think': 7989, 'first': 7969, 'him': 7905, 'most': 7901, 'love': 7896, 'way': 7828, 'act': 7718, 'play': 7695, 'it': 7359, 'thing': 7316, 'made': 7292, 'then': 7267, 'them': 7120, 'too': 6908, 'ani': 6859, 'after': 6779, 'say': 6741, 'know': 6727, 'am': 6548, 'seem': 6434, 'work': 6184, ';': 6031, 'mani': 6029, 'be': 6007, 'come': 5996, 'seen': 5992, 'plot': 5990, 'actor': 5971, 'two': 5963, 'want': 5942, 'take': 5866, 'never': 5794, 'where': 5761, 'littl': 5745, 'year': 5737, 'tri': 5706, 'best': 5694, 'life': 5652, 'ever': 5340, 'give': 5247, 'here': 5187, 'your': 5172, 'better': 5122, 'man': 5083, 'still': 5041, 'over': 5034, 'off': 5005, 'perform': 4973, 'find': 4885, 'these': 4871, 'should': 4814, 'while': 4752, 'whi': 4734, 'feel': 4689, 'actual': 4605, 'part': 4590, 'such': 4585, '--': 4546, 'use': 4535, 'someth': 4494, 'back': 4487, 'through': 4434, 'interest': 4380, 'get': 4309, 'lot': 4290}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.frequencies(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tz.curry\n",
    "def filter_words(whitelist, words):\n",
    "    return (word for word in words if word in whitelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = vocab.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(tz.map(tz.compose(doc2bow, filter_words(most_common)), processed_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_devtest, y_train, y_devtest = train_test_split(features, dataset['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  pipeline.make_pipeline(feature_extraction.DictVectorizer(), naive_bayes.BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('dictvectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('bernoullinb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.83      0.84      2267\n",
      "         pos       0.83      0.86      0.84      2233\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      4500\n",
      "   macro avg       0.84      0.84      0.84      4500\n",
      "weighted avg       0.84      0.84      0.84      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_devtest, clf.predict(X_devtest), target_names=['neg', 'pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE:\n",
      "\n",
      " Pipeline(memory=None,\n",
      " steps=[('dictvectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "    sparse=True)), ('bernoullinb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])\n",
      "     \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.89      0.85      2206\n",
      "         pos       0.89      0.81      0.85      2294\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4500\n",
      "   macro avg       0.85      0.85      0.85      4500\n",
      "weighted avg       0.85      0.85      0.85      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BASELINE:')\n",
    "print('''\n",
    " Pipeline(memory=None,\n",
    " steps=[('dictvectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
    "    sparse=True)), ('bernoullinb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])\n",
    "     ''')\n",
    "print('''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         neg       0.82      0.89      0.85      2206\n",
    "         pos       0.89      0.81      0.85      2294\n",
    "\n",
    "   micro avg       0.85      0.85      0.85      4500\n",
    "   macro avg       0.85      0.85      0.85      4500\n",
    "weighted avg       0.85      0.85      0.85      4500\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tf = feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Possible steps:\n",
    "* lowercasing\n",
    "* stemming\n",
    "* lemmatization\n",
    "* stopword removal\n",
    "* noise removal (ex. html tags)\n",
    "* tokenization\n",
    "* enrichment: \n",
    "    - POS tagging\n",
    "    - Chunking\n",
    "    - Word embedding\n",
    "    - Phrasing\n",
    "\n",
    "Notes:\n",
    "* Test if lowercasing improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
